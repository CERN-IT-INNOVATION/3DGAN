{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a023b05",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi -i 0,1 --query-gpu=gpu_bus_id,power.draw,utilization.gpu,memory.used --format=csv,nounits --loop-ms=1000 > ./gpu_stats/tf32_2GPUs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d8fe54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2075f9d",
   "metadata": {},
   "source": [
    "Test:\n",
    "- Baseline (tf-32)\n",
    "- Precision\n",
    "    - tf32 (default)\n",
    "    - float32\n",
    "    - mixed\n",
    "    - bfloat\n",
    "- Batch size\n",
    "    - 64 (default)\n",
    "    - 96 (from paper)\n",
    "    - 128\n",
    "    - max (power of 2)\n",
    "    - max (non power of 2) \n",
    "    - Test with tf32 and fp32\n",
    "- different number of GPUs\n",
    "    - 1\n",
    "    - 2\n",
    "    - 4\n",
    "    - 8\n",
    "    - 16 (2 nodes)\n",
    "- diferent GPUs (repeat tests)\n",
    "    - A100\n",
    "    - V100\n",
    "    - A10\n",
    "    - best of all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e19dbc",
   "metadata": {},
   "source": [
    "# Total model flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e03a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator_base\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1, 51, 51, 25)]   0         \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 16, 51, 51, 25)    2896      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " zero_padding3d_5 (ZeroPaddi  (None, 16, 51, 51, 27)   0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 8, 47, 46, 22)     23048     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 47, 46, 22)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " zero_padding3d_6 (ZeroPaddi  (None, 8, 47, 46, 24)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 8, 43, 41, 19)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 43, 41, 19)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 8, 39, 36, 14)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 39, 36, 14)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " average_pooling3d (AverageP  (None, 8, 19, 18, 7)     0         \n",
      " ooling3D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 19152)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,096\n",
      "Trainable params: 49,048\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:43.788462: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:43.788634: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:43.839681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.841254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.842818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.844371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.845923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.847471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.849004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.850543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.870729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator FLOPS =  3063004077.5\n",
      "Discriminator FLOPS =  1896724708.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:44.098994: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:44.099141: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:44.150072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.151646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.153212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.154767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.156325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.157889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.159436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.160978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.180549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.018ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gan_models import generator_model, discriminator_model\n",
    "\n",
    "def get_flops(model, model_inputs) -> float:\n",
    "        \"\"\"\n",
    "        Calculate FLOPS [GFLOPs] for a tf.keras.Model or tf.keras.Sequential model\n",
    "        in inference mode. It uses tf.compat.v1.profiler under the hood.\n",
    "        \"\"\"\n",
    "        # if not hasattr(model, \"model\"):\n",
    "        #     raise wandb.Error(\"self.model must be set before using this method.\")\n",
    "\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops)/2\n",
    "    \n",
    "def forward_backward():\n",
    "    \n",
    "    for_flop = 0\n",
    "    total_flop = 0\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "\n",
    "            #model = tf.keras.applications.ResNet50() # change your model here\n",
    "\n",
    "            model = generator_model(256, dformat=\"channels_first\")\n",
    "            \n",
    "            x = tf.constant(np.random.randn(1, 256))\n",
    "            \n",
    "            outputTensor = model([x]) \n",
    "            listOfVariableTensors = model.trainable_weights\n",
    "            gradients = tf.gradients(outputTensor, listOfVariableTensors)\n",
    "\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            total_flop = flops.total_float_ops\n",
    "            print(total_flop)\n",
    "\n",
    "    return for_flop, total_flop\n",
    "    \n",
    "    \n",
    "    \n",
    "#Usage\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #image_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=None)\n",
    "    \n",
    "    x = tf.constant(np.random.randn(1, 256))\n",
    "    noise = np.random.normal(0, 1, (1, 256)).astype(np.float32)\n",
    "    y = tf.constant(np.random.randn(1, 1, 51 , 51, 25))\n",
    "    \n",
    "    #print(x.shape)\n",
    "    \n",
    "    model_g = generator_model(256, dformat=\"channels_first\") #Model(inputs=[latent], outputs=[fake_image], name='Generator')\n",
    "    model_d = discriminator_model(dformat=\"channels_first\")\n",
    "    #model.summary()\n",
    "    print('Generator FLOPS = ', get_flops(model_g,[x]))\n",
    "    print('Discriminator FLOPS = ', get_flops(model_d,[y]))\n",
    "    \n",
    "    #forward_backward()\n",
    "    \n",
    "    #print(get_flops(model, [x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfd790",
   "metadata": {},
   "source": [
    "# Theoretical calculation of floops\n",
    "\n",
    "$ ConvFlops = 2 * NumberKernel * ShapeKernel * OutputShape $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bde3ef",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080f183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00034737586975097656 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151692188712\n",
      "Average per batch was:  0.7735849380493164\n",
      "Time taken by batch 6  was 1.0761363506317139 seconds.\n",
      "Time taken by epoch0 was 39.44963765144348 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.12301487922668457\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae128c",
   "metadata": {},
   "source": [
    "# Results baseline\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 0.77 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.121 +- 0.001\n",
    "\n",
    "GPU Memory = 17921 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 210 and 310 (Normally around 240-260)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45badc",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd91840",
   "metadata": {},
   "source": [
    "## Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692c683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-17 09:58:52.455110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 09:58:53.505032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-17 09:58:53.514180: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "\n",
      "False\n",
      "64\n",
      "2023-04-17 09:58:53.540760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00034308433532714844 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-04-17 09:59:05.850959: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-17 09:59:08.274931: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-17 09:59:08.355888: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151692188712\n",
      "Average per batch was:  1.4568486213684082\n",
      "Time taken by batch 6  was 1.759124755859375 seconds.\n",
      "Time taken by epoch0 was 35.987701654434204 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.27351841926574705\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1c993",
   "metadata": {},
   "source": [
    "## Results float32\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 1.46 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.272 +- 0.001\n",
    "\n",
    "GPU Memory = 9729 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 210 and 260 (Normally around 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84ae01",
   "metadata": {},
   "source": [
    "## Mixed Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effcb11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-17 10:00:10.850275: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 10:00:13.349460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-17 10:00:13.359069: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "\n",
      "True\n",
      "64\n",
      "2023-04-17 10:00:13.389124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003573894500732422 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-04-17 10:00:25.887794: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-17 10:00:28.302371: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-17 10:00:28.383276: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151219571496\n",
      "Average per batch was:  0.685645580291748\n",
      "Time taken by batch 6  was 1.0076277256011963 seconds.\n",
      "Time taken by epoch0 was 37.052306175231934 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.08366184234619141\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32 --use_precision 'mixed_float16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c569c",
   "metadata": {},
   "source": [
    "## Results Mixed Float16\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 0.69 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.085 +- 0.001\n",
    "\n",
    "GPU Memory = 9729 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 230 and 280 (Normally around 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08994a",
   "metadata": {},
   "source": [
    "## Mixed BFloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ac54651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-12 14:57:23.923602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-12 14:57:25.937240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-12 14:57:25.946061: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "\n",
      "2023-04-12 14:57:25.975026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "['/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_000.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_001.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_002.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_003.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_004.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_005.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_006.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_007.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_008.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_009.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_010.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_011.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_012.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_013.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_014.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_015.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_016.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_017.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_018.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_019.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_020.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_021.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_022.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_023.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_024.tfrecords']\n",
      "['/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_025.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_026.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_027.tfrecords']\n",
      "Initialization time is 0.0003504753112792969 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 771, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 387, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'AvgPool3D' used by {{node Discriminator/Discriminator_base/average_pooling3d/AvgPool3D}} with these attrs: [T=DT_BFLOAT16, padding=\"VALID\", data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1]]\n",
      "Registered devices: [CPU, GPU]\n",
      "Registered kernels:\n",
      "  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "  device='GPU'; T in [DT_HALF]\n",
      "  device='GPU'; T in [DT_FLOAT]\n",
      "  device='CPU'; T in [DT_FLOAT]\n",
      "  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "\n",
      "\t [[Discriminator/Discriminator_base/average_pooling3d/AvgPool3D]] [Op:__inference_distributed_train_step_15515]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32 --use_precision 'mixed_bfloat16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434feadd",
   "metadata": {},
   "source": [
    "## Results Mixed BFloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eadcc3",
   "metadata": {},
   "source": [
    "# Batch Size tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79570c",
   "metadata": {},
   "source": [
    "## 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4ebb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "96\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.000438690185546875 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1301\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  3227529574280\n",
      "Average per batch was:  1.2198906898498536\n",
      "Time taken by batch 6  was 1.5227434635162354 seconds.\n",
      "Time taken by epoch0 was 51.18376302719116 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(96, 256)\n",
      "FLOP =  2268707005062\n",
      "Average per batch was:  0.18020858764648437\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 96 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43534791",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca2d34",
   "metadata": {},
   "source": [
    "## 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2aec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "128\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003972053527832031 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303366959848\n",
      "Average per batch was:  1.567598009109497\n",
      "Time taken by batch 6  was 1.8706345558166504 seconds.\n",
      "Time taken by epoch0 was 64.55832934379578 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(128, 256)\n",
      "FLOP =  3024942673414\n",
      "Average per batch was:  0.24149599075317382\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 128 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ee027",
   "metadata": {},
   "source": [
    "17921 / 34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25222b4",
   "metadata": {},
   "source": [
    "## 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6cbb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00036644935607910156 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606716502120\n",
      "Average per batch was:  3.1962491989135744\n",
      "Time taken by batch 6  was 3.4644761085510254 seconds.\n",
      "Time taken by epoch0 was 108.58399653434753 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(256, 256)\n",
      "FLOP =  6049885346822\n",
      "Average per batch was:  0.4699376583099365\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 256 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9139c3",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6837c98",
   "metadata": {},
   "source": [
    "## 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d58534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "512\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00033164024353027344 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "2 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[Identity_27/_62]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_14998]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 512 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2db089",
   "metadata": {},
   "source": [
    "# Batch Size float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce79ed8",
   "metadata": {},
   "source": [
    "## 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b71f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "96\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0004143714904785156 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1301\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  3227529574280\n",
      "Average per batch was:  2.1983806610107424\n",
      "Time taken by batch 6  was 2.5031728744506836 seconds.\n",
      "Time taken by epoch0 was 46.40627479553223 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(96, 256)\n",
      "FLOP =  2268707005062\n",
      "Average per batch was:  0.4226221561431885\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 96 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352aaf73",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac37e3",
   "metadata": {},
   "source": [
    "## 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2413dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "128\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003814697265625 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303366959848\n",
      "Average per batch was:  2.8210868358612062\n",
      "Time taken by batch 6  was 3.1255416870117188 seconds.\n",
      "Time taken by epoch0 was 55.360952615737915 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(128, 256)\n",
      "FLOP =  3024942673414\n",
      "Average per batch was:  0.5526898860931396\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 128 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da344537",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553abaed",
   "metadata": {},
   "source": [
    "## 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d220462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003867149353027344 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606716502120\n",
      "Average per batch was:  5.5624189376831055\n",
      "Time taken by batch 6  was 5.854866981506348 seconds.\n",
      "Time taken by epoch0 was 93.62191557884216 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(256, 256)\n",
      "FLOP =  6049885346822\n",
      "Average per batch was:  1.0930707454681396\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 256 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff8fd2",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512bcc9",
   "metadata": {},
   "source": [
    "## 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb3edeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "512\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00038051605224609375 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "2 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[Identity_27/_62]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_14998]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 512 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fd91c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "373140c4",
   "metadata": {},
   "source": [
    "# Number of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edf5af",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92743edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 2\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00038123130798339844 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303384377418\n",
      "Average per batch was:  0.7977048873901367\n",
      "Time taken by batch 6  was 1.5197126865386963 seconds.\n",
      "Time taken by epoch0 was 61.18161749839783 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  3024942673428\n",
      "Average per batch was:  0.12733020782470703\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b1e44",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fc17ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 4\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003292560577392578 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606768754878\n",
      "Average per batch was:  0.8313645362854004\n",
      "Time taken by batch 6  was 2.3093295097351074 seconds.\n",
      "Time taken by epoch0 was 99.28882384300232 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  6049885346864\n",
      "Average per batch was:  0.12891016006469727\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b030fc",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3747805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 8\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003495216369628906 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  17213537509990\n",
      "Average per batch was:  0.8756521701812744\n",
      "Time taken by batch 6  was 3.901090383529663 seconds.\n",
      "Time taken by epoch0 was 172.69893503189087 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  12099770693736\n",
      "Average per batch was:  0.13445558547973632\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e2433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: gan_main.py [-h] [--multi_node MULTI_NODE]\n",
      "                   [--workers WORKERS [WORKERS ...]] [--index INDEX]\n",
      "                   [--use_gs USE_GS] [--datapath DATAPATH] [--outpath OUTPATH]\n",
      "                   [--nbepochs NBEPOCHS] [--batchsize BATCHSIZE]\n",
      "                   [--use_gpus USE_GPUS]\n",
      "                   [--GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE]\n",
      "                   [--nb_epochs NB_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                   [--latent_size LATENT_SIZE] [--verbose VERBOSE]\n",
      "                   [--nEvents NEVENTS] [--ascale ASCALE] [--yscale YSCALE]\n",
      "                   [--xscale XSCALE] [--xpower XPOWER] [--angscale ANGSCALE]\n",
      "                   [--analyse ANALYSE] [--dformat DFORMAT] [--thresh THRESH]\n",
      "                   [--angtype ANGTYPE] [--particle PARTICLE] [--warm WARM]\n",
      "                   [--lr LR] [--events_per_file EVENTS_PER_FILE] [--name NAME]\n",
      "                   [--g_weights G_WEIGHTS] [--d_weights D_WEIGHTS]\n",
      "                   [--tlab TLAB] [--profiling] [--use_tf32]\n",
      "                   [--use_precision USE_PRECISION]\n",
      "\n",
      "3D GAN Params\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --multi_node MULTI_NODE\n",
      "  --workers WORKERS [WORKERS ...]\n",
      "  --index INDEX\n",
      "  --use_gs USE_GS\n",
      "  --datapath DATAPATH   Data path\n",
      "  --outpath OUTPATH     training output\n",
      "  --nbepochs NBEPOCHS   Number of epochs to train for.\n",
      "  --batchsize BATCHSIZE\n",
      "                        batch size per update\n",
      "  --use_gpus USE_GPUS   Use gpus for training\n",
      "  --GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE\n",
      "  --nb_epochs NB_EPOCHS\n",
      "                        Total Epochs\n",
      "  --batch_size BATCH_SIZE\n",
      "  --latent_size LATENT_SIZE\n",
      "                        latent vector size\n",
      "  --verbose VERBOSE\n",
      "  --nEvents NEVENTS     maximum number of events used in training\n",
      "  --ascale ASCALE       angle scale\n",
      "  --yscale YSCALE       scaling energy\n",
      "  --xscale XSCALE\n",
      "  --xpower XPOWER\n",
      "  --angscale ANGSCALE\n",
      "  --analyse ANALYSE     if analysing\n",
      "  --dformat DFORMAT\n",
      "  --thresh THRESH       threshold for data\n",
      "  --angtype ANGTYPE\n",
      "  --particle PARTICLE\n",
      "  --warm WARM\n",
      "  --lr LR\n",
      "  --events_per_file EVENTS_PER_FILE\n",
      "  --name NAME\n",
      "  --g_weights G_WEIGHTS\n",
      "  --d_weights D_WEIGHTS\n",
      "  --tlab TLAB\n",
      "  --profiling\n",
      "  --use_tf32\n",
      "  --use_precision USE_PRECISION\n"
     ]
    }
   ],
   "source": [
    "!python gan_main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "921883b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfloat16\n",
      "float32\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)\n",
    "print(layer.compute_dtype)\n",
    "print(layer.variable_dtype)\n",
    "\n",
    "print(tf.config.experimental.tensor_float_32_execution_enabled())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  data = './data/penn'\n",
    "  model = 'LSTM'\n",
    "  emsize = 200\n",
    "  nhid = 200\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a3be096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.44\n",
      "75.02\n",
      "224.8809090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/datascience/gpu_stats/tf32_bs96.csv', header=None)\n",
    "\n",
    "#print(df)\n",
    "#power.draw [W]  utilization.gpu [%]\n",
    "\n",
    "power_values = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index > 0:\n",
    "        value = int(row[1][:-2])\n",
    "        if value >= 90:\n",
    "            power_values.append(float(row[0][:-2]))\n",
    "            \n",
    "print(max(power_values))\n",
    "print(min(power_values))\n",
    "print(sum(power_values)/len(power_values))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e601e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
