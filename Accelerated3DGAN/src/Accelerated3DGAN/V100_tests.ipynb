{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6ba132",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca628b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi -i 0,1 --query-gpu=gpu_bus_id,power.draw,utilization.gpu,memory.used --format=csv,nounits --loop-ms=1000 > ./gpu_stats/tf32_2GPUs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ffbe2d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853dbd6",
   "metadata": {},
   "source": [
    "Test:\n",
    "- Baseline (tf-32)\n",
    "- Precision\n",
    "    - tf32 (default)\n",
    "    - float32\n",
    "    - mixed\n",
    "    - bfloat\n",
    "- Batch size\n",
    "    - 64 (default)\n",
    "    - 96 (from paper)\n",
    "    - 128\n",
    "    - max (power of 2)\n",
    "    - max (non power of 2) \n",
    "    - Test with tf32 and fp32\n",
    "- different number of GPUs\n",
    "    - 1\n",
    "    - 2\n",
    "    - 4\n",
    "    - 8\n",
    "    - 16 (2 nodes)\n",
    "- diferent GPUs (repeat tests)\n",
    "    - A100\n",
    "    - V100\n",
    "    - A10\n",
    "    - best of all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31444f3c",
   "metadata": {},
   "source": [
    "# Total model flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c27945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator_base\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1, 51, 51, 25)]   0         \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 16, 51, 51, 25)    2896      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " zero_padding3d_5 (ZeroPaddi  (None, 16, 51, 51, 27)   0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 8, 47, 46, 22)     23048     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 47, 46, 22)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " zero_padding3d_6 (ZeroPaddi  (None, 8, 47, 46, 24)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 8, 43, 41, 19)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 43, 41, 19)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 8, 39, 36, 14)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 39, 36, 14)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " average_pooling3d (AverageP  (None, 8, 19, 18, 7)     0         \n",
      " ooling3D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 19152)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,096\n",
      "Trainable params: 49,048\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:43.788462: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:43.788634: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:43.839681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.841254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.842818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.844371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.845923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.847471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.849004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.850543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.870729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator FLOPS =  3063004077.5\n",
      "Discriminator FLOPS =  1896724708.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:44.098994: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:44.099141: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:44.150072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.151646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.153212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.154767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.156325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.157889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.159436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.160978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.180549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.018ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gan_models import generator_model, discriminator_model\n",
    "\n",
    "def get_flops(model, model_inputs) -> float:\n",
    "        \"\"\"\n",
    "        Calculate FLOPS [GFLOPs] for a tf.keras.Model or tf.keras.Sequential model\n",
    "        in inference mode. It uses tf.compat.v1.profiler under the hood.\n",
    "        \"\"\"\n",
    "        # if not hasattr(model, \"model\"):\n",
    "        #     raise wandb.Error(\"self.model must be set before using this method.\")\n",
    "\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops)/2\n",
    "    \n",
    "def forward_backward():\n",
    "    \n",
    "    for_flop = 0\n",
    "    total_flop = 0\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "\n",
    "            #model = tf.keras.applications.ResNet50() # change your model here\n",
    "\n",
    "            model = generator_model(256, dformat=\"channels_first\")\n",
    "            \n",
    "            x = tf.constant(np.random.randn(1, 256))\n",
    "            \n",
    "            outputTensor = model([x]) \n",
    "            listOfVariableTensors = model.trainable_weights\n",
    "            gradients = tf.gradients(outputTensor, listOfVariableTensors)\n",
    "\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            total_flop = flops.total_float_ops\n",
    "            print(total_flop)\n",
    "\n",
    "    return for_flop, total_flop\n",
    "    \n",
    "    \n",
    "    \n",
    "#Usage\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #image_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=None)\n",
    "    \n",
    "    x = tf.constant(np.random.randn(1, 256))\n",
    "    noise = np.random.normal(0, 1, (1, 256)).astype(np.float32)\n",
    "    y = tf.constant(np.random.randn(1, 1, 51 , 51, 25))\n",
    "    \n",
    "    #print(x.shape)\n",
    "    \n",
    "    model_g = generator_model(256, dformat=\"channels_first\") #Model(inputs=[latent], outputs=[fake_image], name='Generator')\n",
    "    model_d = discriminator_model(dformat=\"channels_first\")\n",
    "    #model.summary()\n",
    "    print('Generator FLOPS = ', get_flops(model_g,[x]))\n",
    "    print('Discriminator FLOPS = ', get_flops(model_d,[y]))\n",
    "    \n",
    "    #forward_backward()\n",
    "    \n",
    "    #print(get_flops(model, [x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba4359",
   "metadata": {},
   "source": [
    "# Theoretical calculation of floops\n",
    "\n",
    "$ ConvFlops = 2 * NumberKernel * ShapeKernel * OutputShape $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b7ada",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3927ba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-18 08:12:14.487141: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 08:12:15.491501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2023-04-18 08:12:15.504996: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "\n",
      "False\n",
      "64\n",
      "2023-04-18 08:12:15.513047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0005552768707275391 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-04-18 08:12:30.126335: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-18 08:12:31.285950: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-18 08:12:31.398404: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151692188712\n",
      "Average per batch was:  1.6414869785308839\n",
      "Time taken by batch 6  was 2.1320993900299072 seconds.\n",
      "Time taken by epoch0 was 50.180081367492676 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.2289442539215088\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dacb55",
   "metadata": {},
   "source": [
    "# Results baseline\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 1.64 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.228 +- 0.001\n",
    "\n",
    "GPU percentage = 100%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4a036",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a37e9",
   "metadata": {},
   "source": [
    "## Float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2a256",
   "metadata": {},
   "source": [
    "## Mixed Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db41e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-18 09:40:41.142622: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 09:40:42.150326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2023-04-18 09:40:42.163405: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "\n",
      "False\n",
      "64\n",
      "2023-04-18 09:40:42.172188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0004858970642089844 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-04-18 09:40:57.186477: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-18 09:40:58.272735: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-18 09:40:58.384442: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151219571496\n",
      "Average per batch was:  1.0108042716979981\n",
      "Time taken by batch 6  was 1.4736812114715576 seconds.\n",
      "Time taken by epoch0 was 57.96173095703125 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.17698349952697753\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_precision 'mixed_float16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb666f",
   "metadata": {},
   "source": [
    "## Results Mixed Float16\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 0.69 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.085 +- 0.001\n",
    "\n",
    "GPU Memory = 9729 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 230 and 280 (Normally around 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98b122",
   "metadata": {},
   "source": [
    "## Mixed BFloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd380f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-18 09:42:43.271593: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 09:42:44.270047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2023-04-18 09:42:44.283920: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "\n",
      "True\n",
      "64\n",
      "2023-04-18 09:42:44.292277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14615 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.000514984130859375 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'AvgPool3D' used by {{node Discriminator/Discriminator_base/average_pooling3d/AvgPool3D}} with these attrs: [T=DT_BFLOAT16, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=\"VALID\", data_format=\"NDHWC\"]\n",
      "Registered devices: [CPU, GPU]\n",
      "Registered kernels:\n",
      "  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "  device='GPU'; T in [DT_HALF]\n",
      "  device='GPU'; T in [DT_FLOAT]\n",
      "  device='CPU'; T in [DT_FLOAT]\n",
      "  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "\n",
      "\t [[Discriminator/Discriminator_base/average_pooling3d/AvgPool3D]] [Op:__inference_distributed_train_step_15515]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32 --use_precision 'mixed_bfloat16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16505d4",
   "metadata": {},
   "source": [
    "## Results Mixed BFloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58492e3",
   "metadata": {},
   "source": [
    "# Batch Size float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828cfd8",
   "metadata": {},
   "source": [
    "## 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2c5801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "96\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0005168914794921875 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1301\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  3227529574280\n",
      "Average per batch was:  2.4195351123809816\n",
      "Time taken by batch 6  was 2.8713173866271973 seconds.\n",
      "Time taken by epoch0 was 64.91560482978821 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(96, 256)\n",
      "FLOP =  2268707005062\n",
      "Average per batch was:  0.3345634460449219\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 96 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f5eeb",
   "metadata": {},
   "source": [
    "## 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e56b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "128\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0005292892456054688 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303366959848\n",
      "Average per batch was:  3.211376667022705\n",
      "Time taken by batch 6  was 3.6741883754730225 seconds.\n",
      "Time taken by epoch0 was 82.87913918495178 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(128, 256)\n",
      "FLOP =  3024942673414\n",
      "Average per batch was:  0.44571523666381835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 128 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec16289",
   "metadata": {},
   "source": [
    "## 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420809cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0005350112915039062 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'Generator/Generator_base/zero_padding3d_3/Pad' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 203, in Train_steps\n",
      "      generated_images = generator(generator_ip, training=False)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n",
      "      return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 3361, in call\n",
      "      return backend.spatial_3d_padding(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3807, in spatial_3d_padding\n",
      "      return tf.compat.v1.pad(x, pattern)\n",
      "Node: 'Generator/Generator_base/zero_padding3d_3/Pad'\n",
      "Detected at node 'Generator/Generator_base/zero_padding3d_3/Pad' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 203, in Train_steps\n",
      "      generated_images = generator(generator_ip, training=False)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n",
      "      return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 3361, in call\n",
      "      return backend.spatial_3d_padding(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3807, in spatial_3d_padding\n",
      "      return tf.compat.v1.pad(x, pattern)\n",
      "Node: 'Generator/Generator_base/zero_padding3d_3/Pad'\n",
      "2 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1536,54,54,40] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node Generator/Generator_base/zero_padding3d_3/Pad}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[Identity_29/_66]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1536,54,54,40] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node Generator/Generator_base/zero_padding3d_3/Pad}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_14966]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 256 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4495479",
   "metadata": {},
   "source": [
    "# Number of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91eaa77",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07ad6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 2\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0005004405975341797 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303384377418\n",
      "Average per batch was:  1.6638442516326903\n",
      "Time taken by batch 6  was 2.676504611968994 seconds.\n",
      "Time taken by epoch0 was 73.85028028488159 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  3024942673428\n",
      "Average per batch was:  0.232596492767334\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad7f88",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9087c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 4\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0004951953887939453 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606768754878\n",
      "Average per batch was:  1.6970230102539063\n",
      "Time taken by batch 6  was 3.8759195804595947 seconds.\n",
      "Time taken by epoch0 was 121.11103916168213 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  6049885346864\n",
      "Average per batch was:  0.2456348419189453\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8883445",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c6c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 8\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0004930496215820312 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  17213537509990\n",
      "Average per batch was:  1.7350628852844239\n",
      "Time taken by batch 6  was 6.286100149154663 seconds.\n",
      "Time taken by epoch0 was 214.03128504753113 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  12099770693736\n",
      "Average per batch was:  0.24730567932128905\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "586a2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: gan_main.py [-h] [--multi_node MULTI_NODE]\n",
      "                   [--workers WORKERS [WORKERS ...]] [--index INDEX]\n",
      "                   [--use_gs USE_GS] [--datapath DATAPATH] [--outpath OUTPATH]\n",
      "                   [--nbepochs NBEPOCHS] [--batchsize BATCHSIZE]\n",
      "                   [--use_gpus USE_GPUS]\n",
      "                   [--GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE]\n",
      "                   [--nb_epochs NB_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                   [--latent_size LATENT_SIZE] [--verbose VERBOSE]\n",
      "                   [--nEvents NEVENTS] [--ascale ASCALE] [--yscale YSCALE]\n",
      "                   [--xscale XSCALE] [--xpower XPOWER] [--angscale ANGSCALE]\n",
      "                   [--analyse ANALYSE] [--dformat DFORMAT] [--thresh THRESH]\n",
      "                   [--angtype ANGTYPE] [--particle PARTICLE] [--warm WARM]\n",
      "                   [--lr LR] [--events_per_file EVENTS_PER_FILE] [--name NAME]\n",
      "                   [--g_weights G_WEIGHTS] [--d_weights D_WEIGHTS]\n",
      "                   [--tlab TLAB] [--profiling] [--use_tf32]\n",
      "                   [--use_precision USE_PRECISION]\n",
      "\n",
      "3D GAN Params\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --multi_node MULTI_NODE\n",
      "  --workers WORKERS [WORKERS ...]\n",
      "  --index INDEX\n",
      "  --use_gs USE_GS\n",
      "  --datapath DATAPATH   Data path\n",
      "  --outpath OUTPATH     training output\n",
      "  --nbepochs NBEPOCHS   Number of epochs to train for.\n",
      "  --batchsize BATCHSIZE\n",
      "                        batch size per update\n",
      "  --use_gpus USE_GPUS   Use gpus for training\n",
      "  --GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE\n",
      "  --nb_epochs NB_EPOCHS\n",
      "                        Total Epochs\n",
      "  --batch_size BATCH_SIZE\n",
      "  --latent_size LATENT_SIZE\n",
      "                        latent vector size\n",
      "  --verbose VERBOSE\n",
      "  --nEvents NEVENTS     maximum number of events used in training\n",
      "  --ascale ASCALE       angle scale\n",
      "  --yscale YSCALE       scaling energy\n",
      "  --xscale XSCALE\n",
      "  --xpower XPOWER\n",
      "  --angscale ANGSCALE\n",
      "  --analyse ANALYSE     if analysing\n",
      "  --dformat DFORMAT\n",
      "  --thresh THRESH       threshold for data\n",
      "  --angtype ANGTYPE\n",
      "  --particle PARTICLE\n",
      "  --warm WARM\n",
      "  --lr LR\n",
      "  --events_per_file EVENTS_PER_FILE\n",
      "  --name NAME\n",
      "  --g_weights G_WEIGHTS\n",
      "  --d_weights D_WEIGHTS\n",
      "  --tlab TLAB\n",
      "  --profiling\n",
      "  --use_tf32\n",
      "  --use_precision USE_PRECISION\n"
     ]
    }
   ],
   "source": [
    "!python gan_main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97872ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfloat16\n",
      "float32\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)\n",
    "print(layer.compute_dtype)\n",
    "print(layer.variable_dtype)\n",
    "\n",
    "print(tf.config.experimental.tensor_float_32_execution_enabled())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fe7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  data = './data/penn'\n",
    "  model = 'LSTM'\n",
    "  emsize = 200\n",
    "  nhid = 200\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65e657e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.44\n",
      "75.02\n",
      "224.8809090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/datascience/gpu_stats/tf32_bs96.csv', header=None)\n",
    "\n",
    "#print(df)\n",
    "#power.draw [W]  utilization.gpu [%]\n",
    "\n",
    "power_values = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index > 0:\n",
    "        value = int(row[1][:-2])\n",
    "        if value >= 90:\n",
    "            power_values.append(float(row[0][:-2]))\n",
    "            \n",
    "print(max(power_values))\n",
    "print(min(power_values))\n",
    "print(sum(power_values)/len(power_values))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52ede4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
