{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7455c99",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f513c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi -i 0,1 --query-gpu=gpu_bus_id,power.draw,utilization.gpu,memory.used --format=csv,nounits --loop-ms=1000 > ./gpu_stats/tf32_2GPUs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe03dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d0f02",
   "metadata": {},
   "source": [
    "Test:\n",
    "- Baseline (tf-32)\n",
    "- Precision\n",
    "    - tf32 (default)\n",
    "    - float32\n",
    "    - mixed\n",
    "    - bfloat\n",
    "- Batch size\n",
    "    - 64 (default)\n",
    "    - 96 (from paper)\n",
    "    - 128\n",
    "    - max (power of 2)\n",
    "    - max (non power of 2) \n",
    "    - Test with tf32 and fp32\n",
    "- different number of GPUs\n",
    "    - 1\n",
    "    - 2\n",
    "    - 4\n",
    "    - 8\n",
    "    - 16 (2 nodes)\n",
    "- diferent GPUs (repeat tests)\n",
    "    - A100\n",
    "    - V100\n",
    "    - A10\n",
    "    - best of all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05e1ec",
   "metadata": {},
   "source": [
    "# Total model flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b72680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator_base\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1, 51, 51, 25)]   0         \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 16, 51, 51, 25)    2896      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 51, 51, 25)    0         \n",
      "                                                                 \n",
      " zero_padding3d_5 (ZeroPaddi  (None, 16, 51, 51, 27)   0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 8, 47, 46, 22)     23048     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 47, 46, 22)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 47, 46, 22)     0         \n",
      "                                                                 \n",
      " zero_padding3d_6 (ZeroPaddi  (None, 8, 47, 46, 24)    0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 8, 43, 41, 19)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 43, 41, 19)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 43, 41, 19)     0         \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 8, 39, 36, 14)     11528     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 39, 36, 14)    32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8, 39, 36, 14)     0         \n",
      "                                                                 \n",
      " average_pooling3d (AverageP  (None, 8, 19, 18, 7)     0         \n",
      " ooling3D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 19152)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,096\n",
      "Trainable params: 49,048\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:43.788462: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:43.788634: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:43.839681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.841254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.842818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.844371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.845923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.847471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.849004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.850543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:43.870729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator FLOPS =  3063004077.5\n",
      "Discriminator FLOPS =  1896724708.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 11:24:44.098994: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-14 11:24:44.099141: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-14 11:24:44.150072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.151646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.153212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.154767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.156325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.157889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.159436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.160978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-14 11:24:44.180549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.018ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gan_models import generator_model, discriminator_model\n",
    "\n",
    "def get_flops(model, model_inputs) -> float:\n",
    "        \"\"\"\n",
    "        Calculate FLOPS [GFLOPs] for a tf.keras.Model or tf.keras.Sequential model\n",
    "        in inference mode. It uses tf.compat.v1.profiler under the hood.\n",
    "        \"\"\"\n",
    "        # if not hasattr(model, \"model\"):\n",
    "        #     raise wandb.Error(\"self.model must be set before using this method.\")\n",
    "\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops)/2\n",
    "    \n",
    "def forward_backward():\n",
    "    \n",
    "    for_flop = 0\n",
    "    total_flop = 0\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "\n",
    "            #model = tf.keras.applications.ResNet50() # change your model here\n",
    "\n",
    "            model = generator_model(256, dformat=\"channels_first\")\n",
    "            \n",
    "            x = tf.constant(np.random.randn(1, 256))\n",
    "            \n",
    "            outputTensor = model([x]) \n",
    "            listOfVariableTensors = model.trainable_weights\n",
    "            gradients = tf.gradients(outputTensor, listOfVariableTensors)\n",
    "\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            total_flop = flops.total_float_ops\n",
    "            print(total_flop)\n",
    "\n",
    "    return for_flop, total_flop\n",
    "    \n",
    "    \n",
    "    \n",
    "#Usage\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #image_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=None)\n",
    "    \n",
    "    x = tf.constant(np.random.randn(1, 256))\n",
    "    noise = np.random.normal(0, 1, (1, 256)).astype(np.float32)\n",
    "    y = tf.constant(np.random.randn(1, 1, 51 , 51, 25))\n",
    "    \n",
    "    #print(x.shape)\n",
    "    \n",
    "    model_g = generator_model(256, dformat=\"channels_first\") #Model(inputs=[latent], outputs=[fake_image], name='Generator')\n",
    "    model_d = discriminator_model(dformat=\"channels_first\")\n",
    "    #model.summary()\n",
    "    print('Generator FLOPS = ', get_flops(model_g,[x]))\n",
    "    print('Discriminator FLOPS = ', get_flops(model_d,[y]))\n",
    "    \n",
    "    #forward_backward()\n",
    "    \n",
    "    #print(get_flops(model, [x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e157c9",
   "metadata": {},
   "source": [
    "# Theoretical calculation of floops\n",
    "\n",
    "$ ConvFlops = 2 * NumberKernel * ShapeKernel * OutputShape $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01680942",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4d9c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-05-02 15:20:42.005676: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 15:20:42.553436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-05-02 15:20:42.562705: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "\n",
      "True\n",
      "64\n",
      "2023-05-02 15:20:42.566966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003962516784667969 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-05-02 15:20:50.119540: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-02 15:20:50.253831: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-05-02 15:20:51.534000: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-05-02 15:20:51.643011: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151692188712\n",
      "Average per batch was:  1.3753693580627442\n",
      "Time taken by batch 6  was 1.6531999111175537 seconds.\n",
      "Time taken by epoch0 was 44.607818603515625 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.2757863521575928\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830a8cb",
   "metadata": {},
   "source": [
    "# Results baseline\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 0.77 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.121 +- 0.001\n",
    "\n",
    "GPU Memory = 17921 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 210 and 310 (Normally around 240-260)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10665ca",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d86f8d",
   "metadata": {},
   "source": [
    "## Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed59e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-05-02 15:28:25.565731: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 15:28:26.100937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-05-02 15:28:26.109964: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "\n",
      "False\n",
      "64\n",
      "2023-05-02 15:28:26.113709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00035119056701660156 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-05-02 15:28:33.690929: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-05-02 15:28:35.053281: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-05-02 15:28:35.156015: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151692188712\n",
      "Average per batch was:  2.048625087738037\n",
      "Time taken by batch 6  was 2.327504873275757 seconds.\n",
      "Time taken by epoch0 was 39.64520788192749 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.3516129493713379\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfbb94",
   "metadata": {},
   "source": [
    "## Results float32\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 1.46 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.272 +- 0.001\n",
    "\n",
    "GPU Memory = 9729 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 210 and 260 (Normally around 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba4596",
   "metadata": {},
   "source": [
    "## Mixed Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427d9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-05-02 15:29:40.566835: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 15:29:41.092051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-05-02 15:29:41.100223: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "\n",
      "True\n",
      "64\n",
      "2023-05-02 15:29:41.104291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00034499168395996094 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-05-02 15:29:49.139676: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-05-02 15:29:50.356478: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-05-02 15:29:50.456333: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  2151219571496\n",
      "Average per batch was:  1.1671818733215331\n",
      "Time taken by batch 6  was 1.4537713527679443 seconds.\n",
      "Time taken by epoch0 was 55.251739740371704 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "FLOP =  1512471336710\n",
      "Average per batch was:  0.16665053367614746\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32 --use_precision 'mixed_float16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8f87a",
   "metadata": {},
   "source": [
    "## Results Mixed Float16\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Number of GPUs = 1\n",
    "\n",
    "FLOPS Training = 2151692188712\n",
    "\n",
    "Time training = 0.69 +- 0.01\n",
    "\n",
    "FLOPS Testing = 1512471336710\n",
    "\n",
    "Time Testing = 0.085 +- 0.001\n",
    "\n",
    "GPU Memory = 9729 MiB\n",
    "\n",
    "GPU percentage = 100%\n",
    "\n",
    "GPU Power = between 230 and 280 (Normally around 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dac90f",
   "metadata": {},
   "source": [
    "## Mixed BFloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a34bb54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-12 14:57:23.923602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-12 14:57:25.937240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-12 14:57:25.946061: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "\n",
      "2023-04-12 14:57:25.975026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "['/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_000.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_001.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_002.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_003.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_004.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_005.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_006.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_007.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_008.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_009.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_010.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_011.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_012.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_013.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_014.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_015.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_016.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_017.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_018.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_019.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_020.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_021.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_022.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_023.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_024.tfrecords']\n",
      "['/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_025.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_026.tfrecords', '/home/datascience/tfrecordsprepro/Ele_VarAngleMeas_100_200_027.tfrecords']\n",
      "Initialization time is 0.0003504753112792969 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 771, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 387, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'AvgPool3D' used by {{node Discriminator/Discriminator_base/average_pooling3d/AvgPool3D}} with these attrs: [T=DT_BFLOAT16, padding=\"VALID\", data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1]]\n",
      "Registered devices: [CPU, GPU]\n",
      "Registered kernels:\n",
      "  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "  device='GPU'; T in [DT_HALF]\n",
      "  device='GPU'; T in [DT_FLOAT]\n",
      "  device='CPU'; T in [DT_FLOAT]\n",
      "  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\n",
      "\n",
      "\t [[Discriminator/Discriminator_base/average_pooling3d/AvgPool3D]] [Op:__inference_distributed_train_step_15515]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32 --use_precision 'mixed_bfloat16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1805c01",
   "metadata": {},
   "source": [
    "## Results Mixed BFloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaecf98",
   "metadata": {},
   "source": [
    "# Batch Size tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7df10",
   "metadata": {},
   "source": [
    "## 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8cfbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "96\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003502368927001953 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1301\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  3227529574280\n",
      "Average per batch was:  2.1724761009216307\n",
      "Time taken by batch 6  was 2.4529504776000977 seconds.\n",
      "Time taken by epoch0 was 62.142056941986084 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(96, 256)\n",
      "FLOP =  2268707005062\n",
      "Average per batch was:  0.42598304748535154\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 96 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54af4c1",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d00e3",
   "metadata": {},
   "source": [
    "## 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf69402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "128\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003390312194824219 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303366959848\n",
      "Average per batch was:  2.8220612049102782\n",
      "Time taken by batch 6  was 3.076624631881714 seconds.\n",
      "Time taken by epoch0 was 78.7440927028656 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(128, 256)\n",
      "FLOP =  3024942673414\n",
      "Average per batch was:  0.557237195968628\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 128 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48770871",
   "metadata": {},
   "source": [
    "17921 / 34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f40766",
   "metadata": {},
   "source": [
    "## 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c432a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003502368927001953 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606716502120\n",
      "Average per batch was:  5.982650709152222\n",
      "Time taken by batch 6  was 6.259533643722534 seconds.\n",
      "Time taken by epoch0 was 149.49399662017822 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(256, 256)\n",
      "FLOP =  6049885346822\n",
      "Average per batch was:  1.2217095375061036\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 256 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7012dc",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0b681",
   "metadata": {},
   "source": [
    "## 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8dcb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "512\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.000354766845703125 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'Generator/Generator_base/up_sampling3d/concat_5' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 254, in Train_steps\n",
      "      for _ in range(2):\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 262, in Train_steps\n",
      "      generated_images = generator(generator_ip, training=True)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n",
      "      return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 3043, in call\n",
      "      return backend.resize_volumes(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3456, in resize_volumes\n",
      "      output = repeat_elements(output, width_factor, axis=4)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3501, in repeat_elements\n",
      "      return concatenate(x_rep, axis)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3313, in concatenate\n",
      "      return tf.concat([to_dense(x) for x in tensors], axis)\n",
      "Node: 'Generator/Generator_base/up_sampling3d/concat_5'\n",
      "Detected at node 'Generator/Generator_base/up_sampling3d/concat_5' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 254, in Train_steps\n",
      "      for _ in range(2):\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 262, in Train_steps\n",
      "      generated_images = generator(generator_ip, training=True)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n",
      "      return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
      "      return self._run_internal_graph(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 3043, in call\n",
      "      return backend.resize_volumes(\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3456, in resize_volumes\n",
      "      output = repeat_elements(output, width_factor, axis=4)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3501, in repeat_elements\n",
      "      return concatenate(x_rep, axis)\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/backend.py\", line 3313, in concatenate\n",
      "      return tf.concat([to_dense(x) for x in tensors], axis)\n",
      "Node: 'Generator/Generator_base/up_sampling3d/concat_5'\n",
      "2 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,8,54,54,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node Generator/Generator_base/up_sampling3d/concat_5}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[Identity_23/_54]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,8,54,54,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node Generator/Generator_base/up_sampling3d/concat_5}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_14998]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 512 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6beacc",
   "metadata": {},
   "source": [
    "# Batch Size float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25bfe34",
   "metadata": {},
   "source": [
    "## 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d71022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "96\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003452301025390625 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1301\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  3227529574280\n",
      "Average per batch was:  3.2105798721313477\n",
      "Time taken by batch 6  was 3.472381830215454 seconds.\n",
      "Time taken by epoch0 was 55.60842442512512 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(96, 256)\n",
      "FLOP =  2268707005062\n",
      "Average per batch was:  0.5621757507324219\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 96 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf1895",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20cb9b",
   "metadata": {},
   "source": [
    "## 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9318794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "128\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003380775451660156 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303366959848\n",
      "Average per batch was:  4.100857496261597\n",
      "Time taken by batch 6  was 4.3832502365112305 seconds.\n",
      "Time taken by epoch0 was 69.76401591300964 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(128, 256)\n",
      "FLOP =  3024942673414\n",
      "Average per batch was:  0.711284589767456\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 128 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68144ce",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d60f4",
   "metadata": {},
   "source": [
    "## 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848906a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003437995910644531 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606716502120\n",
      "Average per batch was:  8.23969235420227\n",
      "Time taken by batch 6  was 8.51417851448059 seconds.\n",
      "Time taken by epoch0 was 132.03434109687805 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(256, 256)\n",
      "FLOP =  6049885346822\n",
      "Average per batch was:  1.4390013694763184\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 256 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f725d7",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd7bf4",
   "metadata": {},
   "source": [
    "## 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85aa0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "512\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00038051605224609375 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "Detected at node 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "    File \"/home/datascience/3DGAN/Accelerated3DGAN/src/Accelerated3DGAN/gan_training.py\", line 216, in Train_steps\n",
      "      gradients = tape.gradient(\n",
      "Node: 'gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2'\n",
      "2 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[Identity_27/_62]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[512,16,51,51,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node gradient_tape/Discriminator/Discriminator_base/conv3d_1/Conv3D/Conv3DBackpropInputV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_14998]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 512 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad07eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e40170c6",
   "metadata": {},
   "source": [
    "# Number of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425fc9c",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8d12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 2\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00034332275390625 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  976\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  4303384377418\n",
      "Average per batch was:  1.4011246681213378\n",
      "Time taken by batch 6  was 2.0233020782470703 seconds.\n",
      "Time taken by epoch0 was 61.3730673789978 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  3024942673428\n",
      "Average per batch was:  0.27940144538879397\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07489530",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace45f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 4\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00033926963806152344 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606768754878\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c5105",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "232cfde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "64\n",
      "Number of devices: 8\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003495216369628906 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  244\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  17213537509990\n",
      "Average per batch was:  0.8756521701812744\n",
      "Time taken by batch 6  was 3.901090383529663 seconds.\n",
      "Time taken by epoch0 was 172.69893503189087 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "FLOP =  12099770693736\n",
      "Average per batch was:  0.13445558547973632\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "!python3 gan_main.py --batchsize 64 --datapath '/home/datascience/tfrecordsprepro/*.tfrecords' --outpath './' --profiling --use_tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1756a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: gan_main.py [-h] [--multi_node MULTI_NODE]\n",
      "                   [--workers WORKERS [WORKERS ...]] [--index INDEX]\n",
      "                   [--use_gs USE_GS] [--datapath DATAPATH] [--outpath OUTPATH]\n",
      "                   [--nbepochs NBEPOCHS] [--batchsize BATCHSIZE]\n",
      "                   [--use_gpus USE_GPUS]\n",
      "                   [--GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE]\n",
      "                   [--nb_epochs NB_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                   [--latent_size LATENT_SIZE] [--verbose VERBOSE]\n",
      "                   [--nEvents NEVENTS] [--ascale ASCALE] [--yscale YSCALE]\n",
      "                   [--xscale XSCALE] [--xpower XPOWER] [--angscale ANGSCALE]\n",
      "                   [--analyse ANALYSE] [--dformat DFORMAT] [--thresh THRESH]\n",
      "                   [--angtype ANGTYPE] [--particle PARTICLE] [--warm WARM]\n",
      "                   [--lr LR] [--events_per_file EVENTS_PER_FILE] [--name NAME]\n",
      "                   [--g_weights G_WEIGHTS] [--d_weights D_WEIGHTS]\n",
      "                   [--tlab TLAB] [--profiling] [--use_tf32]\n",
      "                   [--use_precision USE_PRECISION]\n",
      "\n",
      "3D GAN Params\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --multi_node MULTI_NODE\n",
      "  --workers WORKERS [WORKERS ...]\n",
      "  --index INDEX\n",
      "  --use_gs USE_GS\n",
      "  --datapath DATAPATH   Data path\n",
      "  --outpath OUTPATH     training output\n",
      "  --nbepochs NBEPOCHS   Number of epochs to train for.\n",
      "  --batchsize BATCHSIZE\n",
      "                        batch size per update\n",
      "  --use_gpus USE_GPUS   Use gpus for training\n",
      "  --GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE\n",
      "  --nb_epochs NB_EPOCHS\n",
      "                        Total Epochs\n",
      "  --batch_size BATCH_SIZE\n",
      "  --latent_size LATENT_SIZE\n",
      "                        latent vector size\n",
      "  --verbose VERBOSE\n",
      "  --nEvents NEVENTS     maximum number of events used in training\n",
      "  --ascale ASCALE       angle scale\n",
      "  --yscale YSCALE       scaling energy\n",
      "  --xscale XSCALE\n",
      "  --xpower XPOWER\n",
      "  --angscale ANGSCALE\n",
      "  --analyse ANALYSE     if analysing\n",
      "  --dformat DFORMAT\n",
      "  --thresh THRESH       threshold for data\n",
      "  --angtype ANGTYPE\n",
      "  --particle PARTICLE\n",
      "  --warm WARM\n",
      "  --lr LR\n",
      "  --events_per_file EVENTS_PER_FILE\n",
      "  --name NAME\n",
      "  --g_weights G_WEIGHTS\n",
      "  --d_weights D_WEIGHTS\n",
      "  --tlab TLAB\n",
      "  --profiling\n",
      "  --use_tf32\n",
      "  --use_precision USE_PRECISION\n"
     ]
    }
   ],
   "source": [
    "!python gan_main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e337b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfloat16\n",
      "float32\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)\n",
    "print(layer.compute_dtype)\n",
    "print(layer.variable_dtype)\n",
    "\n",
    "print(tf.config.experimental.tensor_float_32_execution_enabled())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  data = './data/penn'\n",
    "  model = 'LSTM'\n",
    "  emsize = 200\n",
    "  nhid = 200\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "523c0b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.44\n",
      "75.02\n",
      "224.8809090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/datascience/gpu_stats/tf32_bs96.csv', header=None)\n",
    "\n",
    "#print(df)\n",
    "#power.draw [W]  utilization.gpu [%]\n",
    "\n",
    "power_values = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index > 0:\n",
    "        value = int(row[1][:-2])\n",
    "        if value >= 90:\n",
    "            power_values.append(float(row[0][:-2]))\n",
    "            \n",
    "print(max(power_values))\n",
    "print(min(power_values))\n",
    "print(sum(power_values)/len(power_values))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d8197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
